{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Toxicity RNN Model z1",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "JqgwlC-r2Zh5"
      },
      "source": [
        "import logging\n",
        "import re\n",
        "import string\n",
        "import time\n",
        "from typing import Tuple, Union, List, Dict\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "\n",
        "level = logging.INFO\n",
        "logging.basicConfig(level=level)\n",
        "logger = logging.getLogger(__name__)\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H88vE9gjtahJ"
      },
      "source": [
        "embed_size   = 128\n",
        "max_features = 20000\n",
        "epochs       = 10\n",
        "batch_size   = 128\n",
        "max_len      = 500"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5zT5aMRtfv7"
      },
      "source": [
        "def fetch_data() -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
        "    filename = 'jigsaw_subset.csv'\n",
        "    f = open(filename,'r')\n",
        "    records = f.read().split('\\n')\n",
        "    \n",
        "    header  = records[0].split(',')\n",
        "    records = [(record.split(',')[0], re.sub('[0-9\\.]+\\,','',record)) for record in records[1:]]\n",
        "    \n",
        "    train_labels   = []\n",
        "    train_examples = []\n",
        "    test_labels    = []\n",
        "    test_examples  = []\n",
        "    \n",
        "    for label,text in records:\n",
        "        try:\n",
        "            if random.random() <= 0.80:\n",
        "                train_labels.append(float(label))\n",
        "                train_examples.append(text)\n",
        "            else:\n",
        "                test_labels.append(float(label))\n",
        "                test_examples.append(text)\n",
        "        except:\n",
        "            print('[ EXCEPTION ] {}')\n",
        "    \n",
        "    #logger.info(f'There are {train_examples.shape[0]} comments in the training set')\n",
        "    #logger.info(f'There are {test_examples.shape[0]} comments in the testing set')\n",
        "    return np.array(train_examples), np.array(train_labels), np.array(test_examples), np.array(test_labels)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbmH9CX_tkJi"
      },
      "source": [
        "def custom_preprocessing(raw_text: str) -> tf.string:\n",
        "    lowercase = tf.strings.lower(raw_text)\n",
        "    stripped_html = tf.strings.regex_replace(lowercase, '<br />', ' ')\n",
        "    return tf.strings.regex_replace(stripped_html, '[%s]' % re.escape(string.punctuation), '')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nqjtT5ttme3"
      },
      "source": [
        "def init_vectorize_layer(text_dataset: np.ndarray) -> TextVectorization:\n",
        "    text_vectorizer = TextVectorization(max_tokens=max_features,\n",
        "                                        standardize=custom_preprocessing,\n",
        "                                        output_mode='int',\n",
        "                                        output_sequence_length=max_len)\n",
        "    text_vectorizer.adapt(text_dataset)\n",
        "    return text_vectorizer"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znJ8-2fjtorb"
      },
      "source": [
        "def init_model(text_dataset: np.ndarray) -> tf.keras.Model:\n",
        "    vectorize_layer = init_vectorize_layer(text_dataset)\n",
        "    raw_input = tf.keras.Input(shape=(1,), dtype=tf.string)\n",
        "    x = vectorize_layer(raw_input)\n",
        "    x = tf.keras.layers.Embedding(max_features + 1, embed_size)(x)\n",
        "    x = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(100, return_sequences=True))(x)\n",
        "    x = tf.keras.layers.GlobalMaxPooling1D()(x)\n",
        "    predictions = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
        "    model = tf.keras.Model(raw_input, predictions)\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-F0QKWJtZUo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "902c84a4-8509-4a30-d4ad-2ca78bc7ed22"
      },
      "source": [
        "'''\n",
        "def train():\n",
        "    train_examples, train_labels, _, _ = fetch_data()\n",
        "    model = init_model(train_examples)\n",
        "    model.fit(train_examples, train_labels, epochs=epochs, batch_size=batch_size)\n",
        "    tf_model_wrapper = TFModel(model)\n",
        "    tf.saved_model.save(tf_model_wrapper.model, f'saved_models/{int(time.time())}',\n",
        "                        signatures={'serving_default': tf_model_wrapper.prediction})\n",
        "    \n",
        "    logger.info('saving SavedModel to ./saved_models')\n",
        "'''"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\ndef train():\\n    train_examples, train_labels, _, _ = fetch_data()\\n    model = init_model(train_examples)\\n    model.fit(train_examples, train_labels, epochs=epochs, batch_size=batch_size)\\n    tf_model_wrapper = TFModel(model)\\n    tf.saved_model.save(tf_model_wrapper.model, f'saved_models/{int(time.time())}',\\n                        signatures={'serving_default': tf_model_wrapper.prediction})\\n    \\n    logger.info('saving SavedModel to ./saved_models')\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aFzM1EwCtqq2",
        "outputId": "4c9d2bc6-f153-49d9-c4fd-80adb0cd6d6e"
      },
      "source": [
        "train_examples, train_labels, test_examples, test_labels = fetch_data()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ EXCEPTION ] {}\n",
            "[ EXCEPTION ] {}\n",
            "[ EXCEPTION ] {}\n",
            "[ EXCEPTION ] {}\n",
            "[ EXCEPTION ] {}\n",
            "[ EXCEPTION ] {}\n",
            "[ EXCEPTION ] {}\n",
            "[ EXCEPTION ] {}\n",
            "[ EXCEPTION ] {}\n",
            "[ EXCEPTION ] {}\n",
            "[ EXCEPTION ] {}\n",
            "[ EXCEPTION ] {}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XBp6G-StzTx"
      },
      "source": [
        "model = init_model(train_examples)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Avfxt6GuZPu",
        "outputId": "1157fc6d-b26c-4e64-d9c9-dbf04c1e92f9"
      },
      "source": [
        "model.fit(train_examples, train_labels, epochs=epochs, batch_size=batch_size)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "63/63 [==============================] - 159s 3s/step - loss: 0.3430 - accuracy: 0.7420\n",
            "Epoch 2/10\n",
            "63/63 [==============================] - 153s 2s/step - loss: 0.2764 - accuracy: 0.7535\n",
            "Epoch 3/10\n",
            "63/63 [==============================] - 153s 2s/step - loss: 0.2372 - accuracy: 0.7530\n",
            "Epoch 4/10\n",
            "63/63 [==============================] - 153s 2s/step - loss: 0.1905 - accuracy: 0.7538\n",
            "Epoch 5/10\n",
            "63/63 [==============================] - 152s 2s/step - loss: 0.1662 - accuracy: 0.7549\n",
            "Epoch 6/10\n",
            "63/63 [==============================] - 152s 2s/step - loss: 0.1521 - accuracy: 0.7557\n",
            "Epoch 7/10\n",
            "63/63 [==============================] - 152s 2s/step - loss: 0.1457 - accuracy: 0.7557\n",
            "Epoch 8/10\n",
            "63/63 [==============================] - 152s 2s/step - loss: 0.1443 - accuracy: 0.7557\n",
            "Epoch 9/10\n",
            "63/63 [==============================] - 152s 2s/step - loss: 0.1416 - accuracy: 0.7557\n",
            "Epoch 10/10\n",
            "63/63 [==============================] - 151s 2s/step - loss: 0.1405 - accuracy: 0.7557\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f692c33c6d8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84EWnTWXq_ux"
      },
      "source": [
        "class TFModel(tf.Module):\n",
        "    def __init__(self, model: tf.keras.Model) -> None:\n",
        "        self.model = model\n",
        "    \n",
        "    @tf.function(input_signature=[tf.TensorSpec(shape=(1, ), dtype=tf.string)])\n",
        "    def prediction(self, comment: str) -> Dict[str, Union[str, List[float]]]:\n",
        "        return {'prediction': self.model(comment),\n",
        "                'description': 'Prediction range from 0 (non-toxic) to 1 (toxic)'}"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IdxjhftvN3y"
      },
      "source": [
        "tf_model_wrapper = TFModel(model)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VntXNnBL3f_A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27ab0e19-8bea-4819-c93f-b62c07926fb3"
      },
      "source": [
        "!mkdir saved_models"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘saved_models’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aiYVDTg12yE0",
        "outputId": "ad1dfdf3-397b-407f-dba8-d305457419cd"
      },
      "source": [
        "tf.saved_model.save(tf_model_wrapper.model, f'saved_models/{int(time.time())}',\n",
        "                        signatures={'serving_default': tf_model_wrapper.prediction})"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: saved_models/1607001500/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: saved_models/1607001500/assets\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G9gnt9Zq205f",
        "outputId": "451e01e4-2f38-4df3-8961-81ceffc56a0d"
      },
      "source": [
        "!tar -zcvf toxicity_model_z1.tar.gz saved_models/"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "saved_models/\n",
            "saved_models/1607001500/\n",
            "saved_models/1607001500/saved_model.pb\n",
            "saved_models/1607001500/variables/\n",
            "saved_models/1607001500/variables/variables.index\n",
            "saved_models/1607001500/variables/variables.data-00000-of-00001\n",
            "saved_models/1607001500/assets/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CiYvPmupaVC9"
      },
      "source": [
        "#ZEND"
      ],
      "execution_count": 16,
      "outputs": []
    }
  ]
}