{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Toxicity RNN Model z1",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "JqgwlC-r2Zh5"
      },
      "source": [
        "import logging\n",
        "import re\n",
        "import string\n",
        "import time\n",
        "from typing import Tuple, Union, List, Dict\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "\n",
        "level = logging.INFO\n",
        "logging.basicConfig(level=level)\n",
        "logger = logging.getLogger(__name__)\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H88vE9gjtahJ"
      },
      "source": [
        "embed_size   = 128\n",
        "max_features = 20000\n",
        "epochs       = 10\n",
        "batch_size   = 128\n",
        "max_len      = 500"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5zT5aMRtfv7"
      },
      "source": [
        "def fetch_data() -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
        "    filename = 'jigsaw_subset.csv'\n",
        "    f = open(filename,'r')\n",
        "    records = f.read().split('\\n')\n",
        "    \n",
        "    header  = records[0].split(',')\n",
        "    records = [(record.split(',')[0], re.sub('[0-9\\.]+\\,','',record)) for record in records[1:]]\n",
        "    \n",
        "    train_labels   = []\n",
        "    train_examples = []\n",
        "    test_labels    = []\n",
        "    test_examples  = []\n",
        "    \n",
        "    for label,text in records:\n",
        "        try:\n",
        "            if random.random() <= 0.80:\n",
        "                train_labels.append(float(label))\n",
        "                train_examples.append(text)\n",
        "            else:\n",
        "                test_labels.append(float(label))\n",
        "                test_examples.append(text)\n",
        "        except:\n",
        "            print('[ EXCEPTION ] {}')\n",
        "    \n",
        "    #logger.info(f'There are {train_examples.shape[0]} comments in the training set')\n",
        "    #logger.info(f'There are {test_examples.shape[0]} comments in the testing set')\n",
        "    return np.array(train_examples), np.array(train_labels), np.array(test_examples), np.array(test_labels)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbmH9CX_tkJi"
      },
      "source": [
        "def custom_preprocessing(raw_text: str) -> tf.string:\n",
        "    lowercase = tf.strings.lower(raw_text)\n",
        "    stripped_html = tf.strings.regex_replace(lowercase, '<br />', ' ')\n",
        "    return tf.strings.regex_replace(stripped_html, '[%s]' % re.escape(string.punctuation), '')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nqjtT5ttme3"
      },
      "source": [
        "def init_vectorize_layer(text_dataset: np.ndarray) -> TextVectorization:\n",
        "    text_vectorizer = TextVectorization(max_tokens=max_features,\n",
        "                                        standardize=custom_preprocessing,\n",
        "                                        output_mode='int',\n",
        "                                        output_sequence_length=max_len)\n",
        "    text_vectorizer.adapt(text_dataset)\n",
        "    return text_vectorizer"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znJ8-2fjtorb"
      },
      "source": [
        "def init_model(text_dataset: np.ndarray) -> tf.keras.Model:\n",
        "    vectorize_layer = init_vectorize_layer(text_dataset)\n",
        "    raw_input = tf.keras.Input(shape=(1,), dtype=tf.string)\n",
        "    x = vectorize_layer(raw_input)\n",
        "    x = tf.keras.layers.Embedding(max_features + 1, embed_size)(x)\n",
        "    x = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(100, return_sequences=True))(x)\n",
        "    x = tf.keras.layers.GlobalMaxPooling1D()(x)\n",
        "    predictions = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
        "    model = tf.keras.Model(raw_input, predictions)\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-F0QKWJtZUo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "6fbf6626-1123-4bf0-a6e9-118917549ce3"
      },
      "source": [
        "'''\n",
        "def train():\n",
        "    train_examples, train_labels, _, _ = fetch_data()\n",
        "    model = init_model(train_examples)\n",
        "    model.fit(train_examples, train_labels, epochs=epochs, batch_size=batch_size)\n",
        "    tf_model_wrapper = TFModel(model)\n",
        "    tf.saved_model.save(tf_model_wrapper.model, f'saved_models/{int(time.time())}',\n",
        "                        signatures={'serving_default': tf_model_wrapper.prediction})\n",
        "    \n",
        "    logger.info('saving SavedModel to ./saved_models')\n",
        "'''"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\ndef train(self) -> None:\\n    train_examples, train_labels, _, _ = self.fetch_data()\\n    model = self.init_model(train_examples)\\n    model.fit(train_examples, train_labels, epochs=self.epochs, batch_size=self.batch_size)\\n    self.tf_model_wrapper = TFModel(model)\\n    tf.saved_model.save(self.tf_model_wrapper.model, f'saved_models/{int(time.time())}',\\n                        signatures={'serving_default': self.tf_model_wrapper.prediction})\\n    \\n    logger.info('saving SavedModel to saved_models')\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aFzM1EwCtqq2",
        "outputId": "5f4674ed-eb38-4bab-80e4-62c5cff43d3d"
      },
      "source": [
        "train_examples, train_labels, test_examples, test_labels = fetch_data()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ EXCEPTION ] {}\n",
            "[ EXCEPTION ] {}\n",
            "[ EXCEPTION ] {}\n",
            "[ EXCEPTION ] {}\n",
            "[ EXCEPTION ] {}\n",
            "[ EXCEPTION ] {}\n",
            "[ EXCEPTION ] {}\n",
            "[ EXCEPTION ] {}\n",
            "[ EXCEPTION ] {}\n",
            "[ EXCEPTION ] {}\n",
            "[ EXCEPTION ] {}\n",
            "[ EXCEPTION ] {}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XBp6G-StzTx"
      },
      "source": [
        "model = init_model(train_examples)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Avfxt6GuZPu",
        "outputId": "ad075c11-c119-44fd-99f3-2fa3917a4a7e"
      },
      "source": [
        "model.fit(train_examples, train_labels, epochs=epochs, batch_size=batch_size)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "63/63 [==============================] - 156s 2s/step - loss: 0.3387 - accuracy: 0.7477\n",
            "Epoch 2/10\n",
            "63/63 [==============================] - 152s 2s/step - loss: 0.2822 - accuracy: 0.7478\n",
            "Epoch 3/10\n",
            "63/63 [==============================] - 155s 2s/step - loss: 0.2409 - accuracy: 0.7482\n",
            "Epoch 4/10\n",
            "63/63 [==============================] - 158s 3s/step - loss: 0.1922 - accuracy: 0.7482\n",
            "Epoch 5/10\n",
            "63/63 [==============================] - 153s 2s/step - loss: 0.1659 - accuracy: 0.7496\n",
            "Epoch 6/10\n",
            "63/63 [==============================] - 153s 2s/step - loss: 0.1541 - accuracy: 0.7498\n",
            "Epoch 7/10\n",
            "63/63 [==============================] - 152s 2s/step - loss: 0.1485 - accuracy: 0.7498\n",
            "Epoch 8/10\n",
            "63/63 [==============================] - 155s 2s/step - loss: 0.1455 - accuracy: 0.7498\n",
            "Epoch 9/10\n",
            "63/63 [==============================] - 153s 2s/step - loss: 0.1437 - accuracy: 0.7498\n",
            "Epoch 10/10\n",
            "63/63 [==============================] - 152s 2s/step - loss: 0.1428 - accuracy: 0.7498\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f41ccca46a0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IdxjhftvN3y"
      },
      "source": [
        "tf_model_wrapper = TFModel(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VntXNnBL3f_A"
      },
      "source": [
        "!mkdir saved_models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aiYVDTg12yE0",
        "outputId": "50416ba4-b27c-4fd1-faa5-56633cdd5460"
      },
      "source": [
        "tf.saved_model.save(tf_model_wrapper.model, f'saved_models/{int(time.time())}',\n",
        "                        signatures={'serving_default': tf_model_wrapper.prediction})"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: saved_models/1606500237/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: saved_models/1606500237/assets\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G9gnt9Zq205f",
        "outputId": "9aa5ed42-9530-405e-de7c-ae440e44f6dc"
      },
      "source": [
        "!tar -zcvf toxicity_model_z1.tar.gz saved_models/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "saved_models/\n",
            "saved_models/1606500237/\n",
            "saved_models/1606500237/variables/\n",
            "saved_models/1606500237/variables/variables.index\n",
            "saved_models/1606500237/variables/variables.data-00000-of-00001\n",
            "saved_models/1606500237/assets/\n",
            "saved_models/1606500237/saved_model.pb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CiYvPmupaVC9"
      },
      "source": [
        "#ZEND"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}